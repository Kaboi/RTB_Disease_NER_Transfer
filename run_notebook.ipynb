{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! pwd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! nvcc --version"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    capability = torch.cuda.get_device_capability(device.index)\n",
    "    supports_fp16 = capability[0] >= 7  # FP16 support requires compute capability 7.0 or higher\n",
    "    print(f\"GPU supports FP16: {supports_fp16}\")\n",
    "else:\n",
    "    print(\"No GPU available\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Install transformers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/huggingface/transformers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Install the other required libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! pip install --upgrade transformers\n",
    "! pip install transformers[sentencepiece]\n",
    "! pip install transformers[torch]\n",
    "# ! pip install seqeval\n",
    "! pip install seqeval[gpu]\n",
    "! pip install conllu\n",
    "! pip install seaborn\n",
    "! pip install wandb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Login to wandb and set parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# login to wandb\n",
    "import wandb\n",
    "wandb.login()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %env WANDB_PROJECT=RTB-NER-Transfer-Learning\n",
    "# %env WANDB_PROJECT=RTB-NER-DEBUG\n",
    "# %env WANDB_TAGS =Transfer Learning,train,BERT\n",
    "# %env WANDB_WATCH=all\n",
    "\n",
    "#try this for sweeps\n",
    "%env WANDB_CONSOLE=\"off\"\n",
    "%env WANDB_DISABLE_SERVICE=true"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %env WANDB_PROJECT=WNUT-NER-Transfer-Learning\n",
    "# %env WANDB_TAGS = [\"Transfer Learning\", \"BERT\", \"train\", \"WNUT\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocess the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! tr '\\t' ' ' < data_10/ciat_ner_diseases-output-iob-tags-10_train.txt > data_10/train.txt.tmp\n",
    "# ! tr '\\t' ' ' < data_10/ciat_ner_diseases-output-iob-tags-10_test.txt > data_10/test.txt.tmp\n",
    "# ! tr '\\t' ' ' < data_10/ciat_ner_diseases-output-iob-tags-10_validate.txt > data_10/dev.txt.tmp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! python scripts/preprocess.py data_10/train.txt.tmp bert-large-cased 128 > data_10/train.txt\n",
    "# ! python scripts/preprocess.py data_10/test.txt.tmp bert-large-cased 128 > data_10/test.txt\n",
    "# ! python scripts/preprocess.py data_10/dev.txt.tmp bert-large-cased 128 > data_10/dev.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# ! tr '\\t' ' ' < data_30/ciat_ner_diseases-output-iob-tags-30_train.txt > data_30/train.txt.tmp\n",
    "# ! tr '\\t' ' ' < data_30/ciat_ner_diseases-output-iob-tags-30_test.txt > data_30/test.txt.tmp\n",
    "# ! tr '\\t' ' ' < data_30/ciat_ner_diseases-output-iob-tags-30_validate.txt > data_30/dev.txt.tmp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T14:20:27.920154925Z",
     "start_time": "2023-07-16T14:20:27.299471607Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# ! python scripts/preprocess.py data_30/train.txt.tmp bert-large-cased 128 > data_30/bert_large_cased/128/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp bert-large-cased 128 > data_30/bert_large_cased/128/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp bert-large-cased 128 > data_30/bert_large_cased/128/dev.txt\n",
    "#\n",
    "# ! python scripts/preprocess.py data_30/train.txt.tmp bert-large-cased 256 > data_30/bert_large_cased/256/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp bert-large-cased 256 > data_30/bert_large_cased/256/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp bert-large-cased 256 > data_30/bert_large_cased/256/dev.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T14:24:40.144912296Z",
     "start_time": "2023-07-16T14:24:34.091041752Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# ! python scripts/preprocess.py data_30/train.txt.tmp bert-large-uncased 128 > data_30/bert_large_uncased/128/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp bert-large-uncased 128 > data_30/bert_large_uncased/128/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp bert-large-uncased 128 > data_30/bert_large_uncased/128/dev.txt\n",
    "#\n",
    "# ! python scripts/preprocess.py data_30/train.txt.tmp bert-large-uncased 256 > data_30/bert_large_uncased/256/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp bert-large-uncased 256 > data_30/bert_large_uncased/256/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp bert-large-uncased 256 > data_30/bert_large_uncased/256/dev.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T14:29:05.158713883Z",
     "start_time": "2023-07-16T14:28:59.782009238Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# ! python scripts/preprocess.py data_30/train.txt.tmp allenai/scibert_scivocab_uncased 128 > data_30/scibert_scivocab_uncased/128/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp allenai/scibert_scivocab_uncased 128 > data_30/scibert_scivocab_uncased/128/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp allenai/scibert_scivocab_uncased 128 > data_30/scibert_scivocab_uncased/128/dev.txt\n",
    "\n",
    "# ! python scripts/preprocess.py data_30/train.txt.tmp allenai/scibert_scivocab_uncased 256 > data_30/scibert_scivocab_uncased/256/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp allenai/scibert_scivocab_uncased 256 > data_30/scibert_scivocab_uncased/256/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp allenai/scibert_scivocab_uncased 256 > data_30/scibert_scivocab_uncased/256/dev.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T14:31:19.190530699Z",
     "start_time": "2023-07-16T14:31:10.882372928Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# ! python scripts/preprocess.py data_30/train.txt.tmp allenai/scibert_scivocab_cased 128 > data_30/scibert_scivocab_cased/128/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp allenai/scibert_scivocab_cased 128 > data_30/scibert_scivocab_cased/128/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp allenai/scibert_scivocab_cased 128 > data_30/scibert_scivocab_cased/128/dev.txt\n",
    "#\n",
    "# ! python scripts/preprocess.py data_30/train.txt.tmp allenai/scibert_scivocab_cased 256 > data_30/scibert_scivocab_cased/256/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp allenai/scibert_scivocab_cased 256 > data_30/scibert_scivocab_cased/256/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp allenai/scibert_scivocab_cased 256 > data_30/scibert_scivocab_cased/256/dev.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T14:32:19.467209753Z",
     "start_time": "2023-07-16T14:32:10.271399906Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n"
     ]
    }
   ],
   "source": [
    "# ! python scripts/preprocess.py data_30/train.txt.tmp microsoft/deberta-v2-xlarge 128 > data_30/deberta_v2_xlarge/128/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp microsoft/deberta-v2-xlarge 128 > data_30/deberta_v2_xlarge/128/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp microsoft/deberta-v2-xlarge 128 > data_30/deberta_v2_xlarge/128/dev.txt\n",
    "#\n",
    "# ! python scripts/preprocess.py data_30/train.txt.tmp microsoft/deberta-v2-xlarge 256 > data_30/deberta_v2_xlarge/256/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp microsoft/deberta-v2-xlarge 256 > data_30/deberta_v2_xlarge/256/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp microsoft/deberta-v2-xlarge 256 > data_30/deberta_v2_xlarge/256/dev.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T14:33:08.950039223Z",
     "start_time": "2023-07-16T14:33:01.409205504Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# ! python scripts/preprocess.py data_30/train.txt.tmp roberta-large 128 > data_30/roberta_large/128/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp roberta-large 128 > data_30/roberta_large/128/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp roberta-large 128 > data_30/roberta_large/128/dev.txt\n",
    "#\n",
    "# ! python scripts/preprocess.py data_30/train.txt.tmp roberta-large 256 > data_30/roberta_large/256/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp roberta-large 256 > data_30/roberta_large/256/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp roberta-large 256 > data_30/roberta_large/256/dev.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T14:33:58.660084214Z",
     "start_time": "2023-07-16T14:33:50.169199679Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# ! python scripts/preprocess.py data_30/train.txt.tmp google/electra-base-discriminator 128 > data_30/electra_base/128/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp google/electra-base-discriminator 128 > data_30/electra_base/128/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp google/electra-base-discriminator 128 > data_30/electra_base/128/dev.txt\n",
    "#\n",
    "# ! python scripts/preprocess.py data_30/train.txt.tmp google/electra-base-discriminator 256 > data_30/electra_base/256/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp google/electra-base-discriminator 256 > data_30/electra_base/256/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp google/electra-base-discriminator 256 > data_30/electra_base/256/dev.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T14:35:30.005139783Z",
     "start_time": "2023-07-16T14:35:24.653189588Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# ! python scripts/preprocess.py data_30/train.txt.tmp google/electra-large-discriminator 128 > data_30/electra_large/128/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp google/electra-large-discriminator 128 > data_30/electra_large/128/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp google/electra-large-discriminator 128 > data_30/electra_large/128/dev.txt\n",
    "#\n",
    "# ! python scripts/preprocess.py data_30/train.txt.tmp google/electra-large-discriminator 256 > data_30/electra_large/256/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp google/electra-large-discriminator 256 > data_30/electra_large/256/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp google/electra-large-discriminator 256 > data_30/electra_large/256/dev.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T14:36:05.261247193Z",
     "start_time": "2023-07-16T14:36:00.240243767Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "/home/leroy/miniconda3/envs/deep_pdp/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\r\n",
      "  warnings.warn(\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "/home/leroy/miniconda3/envs/deep_pdp/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\r\n",
      "  warnings.warn(\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "/home/leroy/miniconda3/envs/deep_pdp/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\r\n",
      "  warnings.warn(\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n"
     ]
    }
   ],
   "source": [
    "# ! python scripts/preprocess.py data_30/train.txt.tmp KISTI-AI/Scideberta-full 128 > data_30/sciberta_full/128/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp KISTI-AI/Scideberta-full 128 > data_30/sciberta_full/128/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp KISTI-AI/Scideberta-full 128 > data_30/sciberta_full/128/dev.txt\n",
    "#\n",
    "# ! python scripts/preprocess.py data_30/train.txt.tmp KISTI-AI/Scideberta-full 256 > data_30/sciberta_full/256/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp KISTI-AI/Scideberta-full 256 > data_30/sciberta_full/256/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp KISTI-AI/Scideberta-full 256 > data_30/sciberta_full/256/dev.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T14:36:57.443793110Z",
     "start_time": "2023-07-16T14:36:47.694755794Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# ! python scripts/preprocess.py data_30/train.txt.tmp microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext 128 > data_30/PubMedBert_base_uncased/128/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext 128 > data_30/PubMedBert_base_uncased/128/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext 128 > data_30/PubMedBert_base_uncased/128/dev.txt\n",
    "#\n",
    "# ! python scripts/preprocess.py data_30/train.txt.tmp microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext 256 > data_30/PubMedBert_base_uncased/256/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext 256 > data_30/PubMedBert_base_uncased/256/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext 256 > data_30/PubMedBert_base_uncased/256/dev.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T14:37:42.675396928Z",
     "start_time": "2023-07-16T14:37:37.752438563Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# ! python scripts/preprocess.py data_30/train.txt.tmp dmis-lab/biobert-base-cased-v1.2 128 > data_30/biobert_base_cased/128/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp dmis-lab/biobert-base-cased-v1.2 128 > data_30/biobert_base_cased/128/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp dmis-lab/biobert-base-cased-v1.2 128 > data_30/biobert_base_cased/128/dev.txt\n",
    "#\n",
    "# ! python scripts/preprocess.py data_30/train.txt.tmp dmis-lab/biobert-base-cased-v1.2 256 > data_30/biobert_base_cased/256/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp dmis-lab/biobert-base-cased-v1.2 256 > data_30/biobert_base_cased/256/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp dmis-lab/biobert-base-cased-v1.2 256 > data_30/biobert_base_cased/256/dev.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T14:38:40.925390933Z",
     "start_time": "2023-07-16T14:38:32.078819398Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "/home/leroy/miniconda3/envs/deep_pdp/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\r\n",
      "  warnings.warn(\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "/home/leroy/miniconda3/envs/deep_pdp/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\r\n",
      "  warnings.warn(\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "/home/leroy/miniconda3/envs/deep_pdp/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\r\n",
      "  warnings.warn(\r\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n"
     ]
    }
   ],
   "source": [
    "! python scripts/preprocess.py data_30/train.txt.tmp microsoft/deberta-v3-large 128 > data_30/deberta_v3_large/128/train.txt\n",
    "! python scripts/preprocess.py data_30/test.txt.tmp microsoft/deberta-v3-large 128 > data_30/deberta_v3_large/128/test.txt\n",
    "! python scripts/preprocess.py data_30/dev.txt.tmp microsoft/deberta-v3-large 128 > data_30/deberta_v3_large/128/dev.txt\n",
    "#\n",
    "# ! python scripts/preprocess.py data_30/train.txt.tmp microsoft/deberta-v3-large 256 > data_30/deberta_v3_large/256/train.txt\n",
    "# ! python scripts/preprocess.py data_30/test.txt.tmp microsoft/deberta-v3-large 256 > data_30/deberta_v3_large/256/test.txt\n",
    "# ! python scripts/preprocess.py data_30/dev.txt.tmp microsoft/deberta-v3-large 256 > data_30/deberta_v3_large/256/dev.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T14:39:53.099065324Z",
     "start_time": "2023-07-16T14:39:45.792537781Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! tr '\\t' ' ' < data_20/ciat_ner_diseases-output-iob-tags-20_test.txt > data_20/test.txt.tmp\n",
    "# ! tr '\\t' ' ' < data_20/ciat_ner_diseases-output-iob-tags-20_train.txt > data_20/train.txt.tmp\n",
    "# ! tr '\\t' ' ' < data_20/ciat_ner_diseases-output-iob-tags-20_validate.txt > data_20/dev.txt.tmp\n",
    "\n",
    "# do in shell\n",
    "# export MAX_LENGTH=128\n",
    "# export BERT_MODEL=bert-base-cased\n",
    "# python3 scripts/preprocess.py data_20/train.txt.tmp $BERT_MODEL $MAX_LENGTH > data_20/train.txt\n",
    "# python3 scripts/preprocess.py data_20/dev.txt.tmp $BERT_MODEL $MAX_LENGTH > data_20/dev.txt\n",
    "# python3 scripts/preprocess.py data_20/test.txt.tmp $BERT_MODEL $MAX_LENGTH > data_20/test.txt\n",
    "\n",
    "# ! cat data_20/train.txt data_20/dev.txt data_20/test.txt | cut -d \" \" -f 2 | grep -v \"^$\"| sort | uniq > data_20/labels.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! tr '\\t' ' ' < data_4K/ciat_ner_diseases-output-iob-tags-4000_train.txt > data_4K/train.txt.tmp\n",
    "# ! tr '\\t' ' ' < data_4K/ciat_ner_diseases-output-iob-tags-4000_test.txt > data_4K/test.txt.tmp\n",
    "# ! tr '\\t' ' ' < data_4K/ciat_ner_diseases-output-iob-tags-4000_validate.txt > data_4K/dev.txt.tmp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! python scripts/preprocess.py data_4K/train.txt.tmp allenai/longformer-base-4096 4096 > data_4K/longformer/4096/train.txt\n",
    "# ! python scripts/preprocess.py data_4K/test.txt.tmp allenai/longformer-base-4096 4096 > data_4K/longformer/4096/test.txt\n",
    "# ! python scripts/preprocess.py data_4K/dev.txt.tmp allenai/longformer-base-4096 4096 > data_4K/longformer/4096/dev.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run the training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! python run_ner.py ./data_30/bert_large_cased/train_config_bert_large_cased_128.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! python run_ner.py ./data_30/bert_large_cased/train_config_bert_large_cased_256.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! python run_ner.py ./data_30/bert_large_uncased/train_config_bert_large_uncased_128.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! python run_ner.py ./data_30/bert_large_uncased/train_config_bert_large_uncased_256.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! python run_ner.py ./data_30/scibert_scivocab_uncased/train_config_scibert_scivocab_uncased_128.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! python run_ner.py ./data_30/scibert_scivocab_uncased/train_config_scibert_scivocab_uncased_256.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! python run_ner.py ./data_30/scibert_scivocab_cased/train_config_scibert_scivocab_cased_128.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! python run_ner.py ./data_30/scibert_scivocab_cased/train_config_scibert_scivocab_cased_256.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! python run_ner.py ./data_30/deberta_v2_xlarge/train_config_deberta_v2_xlarge_128.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! python run_ner.py ./data_30/deberta_v2_xlarge/train_config_deberta_v2_xlarge_256.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! python run_ner.py ./data_30/roberta_large/train_config_roberta_large_128.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! python run_ner.py ./data_30/roberta_large/train_config_roberta_large_256.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! python run_ner.py ./data_30/electra_base/train_config_electra_base_128.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! python run_ner.py ./data_30/electra_base/train_config_electra_base_256.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! python run_ner.py ./data_30/electra_large/train_config_electra_large_128.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! python run_ner.py ./data_30/electra_large/train_config_electra_large_256.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! python run_ner.py ./data_30/sciberta_full/train_config_sciberta_full_128.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! python run_ner.py ./data_30/sciberta_full/train_config_sciberta_full_256.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! python run_ner.py ./data_30/PubMedBert_base_uncased/train_config_PubMedBert_base_uncased_128.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! python run_ner.py ./data_30/PubMedBert_base_uncased/train_config_PubMedBert_base_uncased_256.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! python run_ner.py ./data_30/biobert_base_cased/train_config_biobert_base_128.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! python run_ner.py ./data_30/biobert_base_cased/train_config_biobert_base_256.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! python run_ner.py ./data_30/deberta_v3_large/train_config_deberta_v3_large_128.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! python run_ner.py ./data_30/deberta_v3_large/train_config_deberta_v3_large_256.json\n",
    "# # ! python run_ner.py ./data_30/deberta_v3_large/train_config_deberta_v3_large_256_8b.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! python run_ner.py ./data_4K/longformer/train_config_longformer_4096.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! python sweep.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! runpodctl stop pod $RUNPOD_POD_ID"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
